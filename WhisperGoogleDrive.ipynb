{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewMayneProjects/Whisper/blob/main/WhisperGoogleDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're looking at this on GitHub and new to Python Notebooks or Colab, click the Google Colab badge above ðŸ‘†\n",
        "\n",
        "#OpenAI Whisper and Google Drive integration\n",
        "\n",
        "###This notebook will transcribe all the audio files in a Google Drive folder and save them.\n",
        "\n",
        "*Note: This requires giving the application permission to connect to your drive. Only you will have access to the contents of your drive, but please read the warnings carefully.*\n",
        "\n",
        "This notebook application:\n",
        "1. Connects to your Google Drive when you give it permission.\n",
        "2. Creates a WhisperAudio folder and two subfolders (ProcessedAudio and TextFiles.)\n",
        "3. When you run the application it will search for all the audio files (.mp3 and .m4a) in your WhisperAudio folder, transcribe them and then move the file to /ProcessedAudio and save the transcript to /TextFiles."
      ],
      "metadata": {
        "id": "mwJYcVNBcKpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Install the required code libraries"
      ],
      "metadata": {
        "id": "6uzeghNJgTgD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDZ2XzKIDLsA"
      },
      "outputs": [],
      "source": [
        "!pip install youtube_dl\n",
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install librosa\n",
        "\n",
        "import whisper\n",
        "import time\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import re\n",
        "model = whisper.load_model(\"small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Allow access to your Google Drive"
      ],
      "metadata": {
        "id": "4rhtpcTkgKrG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YeXdboeC8eX",
        "outputId": "a3640e90-c14b-4639-9332-703dfb666344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load all the audio file paths in a Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) # This will prompt for authorization.\n",
        "\n",
        "# This will create the WhisperAudio files if they don't exist.\n",
        "folders =  [\"WhisperAudio/\", \"WhisperAudio/ProcessedAudio/\", \"WhisperAudio/TextFiles/\"]\n",
        "for folder in folders:\n",
        "  path = \"/content/drive/MyDrive/\" + folder\n",
        "  if not os.path.exists(path): # Create the folder if it does not exist\n",
        "    os.mkdir(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Upload any audio files you want transcribed in the \"WhisperAudio\" folder in your Google Drive.\n",
        "\n",
        "##4. Let the application search for new files."
      ],
      "metadata": {
        "id": "Qg3uGr5If5oM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBmTS6IuPh3M",
        "outputId": "ee72a2e3-b057-44af-be29-7a5d94b5b222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/WhisperAudio/puasetest.m4a\n"
          ]
        }
      ],
      "source": [
        "# Assuming the audio files are in a folder called \"WhisperAudio\" in the root of the drive\n",
        "audio_folder = \"/content/drive/MyDrive/WhisperAudio/\"\n",
        "\n",
        "# Get a list of all the file paths and names in the folder\n",
        "import os\n",
        "audio_files = []\n",
        "audio_names = []\n",
        "for file in os.listdir(audio_folder):\n",
        "  if file.endswith(\".m4a\") or file.endswith(\".mp3\"):\n",
        "    audio_files.append(audio_folder + file)\n",
        "    audio_names.append(file)\n",
        "\n",
        "for f in audio_files:    \n",
        "  print(f)\n",
        "\n",
        "if len(audio_files) == 0:\n",
        "  print(\"You have no files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Transcribe the audio files and save them to your Google Drive"
      ],
      "metadata": {
        "id": "iWxRfn7GgugF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zr2cOYRJDeY5"
      },
      "outputs": [],
      "source": [
        "# Loop through the audio files, split each audio file based on pauses in speech then transcribe them with Whisper.\n",
        "for i, file in enumerate(audio_files): # For each audio file\n",
        "  print(f\"Processing {audio_names[i]}...\")\n",
        "  # Load the audio file and convert it to 16 kHz mono\n",
        "  audio, sr = librosa.load(file, sr=16000, mono=True)\n",
        "  # Detect pauses and split the audio. We use a threshold of -30 dB and a minimum pause length of 0.5 seconds.\n",
        "  pauses = librosa.effects.split(audio, top_db=30, frame_length=2048, hop_length=128)\n",
        "  # Transcribe each segment and concatenate the results\n",
        "  transcription = \"\"\n",
        "  for start, end in pauses: # For each segment\n",
        "    segment = audio[start:end]\n",
        "    # Save the segment as a temporary wav file\n",
        "    temp_file = \"temp.wav\"\n",
        "    sf.write(temp_file, segment, sr, subtype='PCM_16')\n",
        "    if os.path.getsize(temp_file) > 10000:\n",
        "      #continue\n",
        "      # Transcribe the segment with Whisper\n",
        "      result = model.transcribe(temp_file)\n",
        "      text = result[\"text\"]\n",
        "      # Append the text to the transcription\n",
        "      print(len(transcription.split(\" \")), \"words processed\")\n",
        "      transcription += text.strip() + \" \"\n",
        "      # Delete the temporary file\n",
        "      os.remove(temp_file)\n",
        "  # Print the transcription\n",
        "  print(f\"Transcription of {audio_names[i]}:\\n\")\n",
        "  print(transcription)\n",
        "  print(\"\\n\")\n",
        " \n",
        "  # Convert the spaces between sections into paragraph breaks and save the transcription as a txt document in the same folder as MyAudio.\n",
        "  transcription = re.sub(r\"\\s\\s+\", \"\\n\\n\", transcription) # Replace multiple spaces with newlines\n",
        "  text_file = audio_folder + \"/TextFiles/\" + audio_names[i][:-4] + \".txt\" # Create the text file name\n",
        "  with open(text_file, \"w\") as f: # Write the transcription to the text file\n",
        "    f.write(transcription)\n",
        "  print(f\"Saved transcription as {text_file}\")\n",
        "\n",
        "# Move the audio files to \"/content/drive/MyDrive/WhisperAudio/Processed\"\n",
        "import shutil\n",
        "processed_folder = \"/content/drive/MyDrive/WhisperAudio/ProcessedAudio/\"\n",
        "if not os.path.exists(processed_folder): # Create the folder if it does not exist\n",
        "  os.mkdir(processed_folder)\n",
        "for file in audio_files: # Move each audio file to the processed folder\n",
        "  shutil.move(file, processed_folder + os.path.basename(file))\n",
        "  print(f\"Moved {file} to {processed_folder}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}